{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15f20b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import os\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.colors import to_rgba\n",
    "from IPython.display import set_matplotlib_formats\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e14fd34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import flax\n",
    "except ModuleNotFoundError: # Install flax if missing\n",
    "    !pip install --quiet flax\n",
    "    import flax\n",
    "\n",
    "from flax import linen as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de9858e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jax\n",
      "  Downloading jax-0.4.6.tar.gz (1.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /home/iiserbpr/anaconda3/lib/python3.9/site-packages (from jax) (1.21.5)\n",
      "Collecting opt_einsum\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m883.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.5 in /home/iiserbpr/anaconda3/lib/python3.9/site-packages (from jax) (1.9.1)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jax: filename=jax-0.4.6-py3-none-any.whl size=1432714 sha256=2ddeefcf18e5bcf9f0ecd02be51b2f95f4230b7c988d88ea074cad47b39f926d\n",
      "  Stored in directory: /home/iiserbpr/.cache/pip/wheels/68/2c/93/17deec4d117dc0675ed79e8e2af1e62fb1c41ed3955c540de0\n",
      "Successfully built jax\n",
      "Installing collected packages: opt_einsum, jax\n",
      "Successfully installed jax-0.4.6 opt_einsum-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df0b5e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "jax requires jaxlib to be installed. See https://github.com/google/jax#installation for installation instructions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/lib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0;32mimport\u001b[0m \u001b[0mjaxlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjaxlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'jaxlib'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4263/4087857324.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# We want the exported object to be the class, so we first import the module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# to make sure a later import doesn't overwrite the class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_config_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_config_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# TODO(phawkins): fix users of this alias and delete this file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNamedTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjax_jit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransfer_guard_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/lib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;32mimport\u001b[0m \u001b[0mjaxlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjaxlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m   raise ModuleNotFoundError(\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;34m'jax requires jaxlib to be installed. See '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;34m'https://github.com/google/jax#installation for installation instructions.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: jax requires jaxlib to be installed. See https://github.com/google/jax#installation for installation instructions."
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "793db91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jax[cpu] in /home/iiserbpr/anaconda3/lib/python3.9/site-packages (0.4.6)\n",
      "Requirement already satisfied: opt-einsum in /home/iiserbpr/anaconda3/lib/python3.9/site-packages (from jax[cpu]) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/iiserbpr/anaconda3/lib/python3.9/site-packages (from jax[cpu]) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.5 in /home/iiserbpr/anaconda3/lib/python3.9/site-packages (from jax[cpu]) (1.9.1)\n",
      "Collecting jaxlib==0.4.6\n",
      "  Downloading jaxlib-0.4.6-cp39-cp39-manylinux2014_x86_64.whl (62.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jaxlib\n",
      "Successfully installed jaxlib-0.4.6\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade \"jax[cpu]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b5eec92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Number: 1 -0.18471177\n",
      "Random Number: 2 -0.18471177\n",
      "Random Number: 3 -0.18471177\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "rng = jax.random.PRNGKey(42)\n",
    "\n",
    "\n",
    "random1 = jax.random.normal(rng)\n",
    "random2 = jax.random.normal(rng)\n",
    "random3 = jax.random.normal(rng)\n",
    "print(\"Random Number: 1\", random1)\n",
    "print(\"Random Number: 2\", random2)\n",
    "print(\"Random Number: 3\", random3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8744240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input [0. 1. 2.]\n",
      "Output 12.666667\n"
     ]
    }
   ],
   "source": [
    "def simple_graph(x):\n",
    "    x = x + 2\n",
    "    x = x ** 2\n",
    "    x = x + 3\n",
    "    y = x.mean()\n",
    "    return y\n",
    "\n",
    "inp = jnp.arange(3, dtype=jnp.float32)\n",
    "print('Input', inp)\n",
    "print('Output', simple_graph(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6ceaf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input [0. 1. 2. 3.]\n",
      "Output 6.5\n"
     ]
    }
   ],
   "source": [
    "def another_graph(x):\n",
    "    x = x**2\n",
    "    x = x+3\n",
    "    x = x.mean()\n",
    "    y = float(x)\n",
    "    return y\n",
    "\n",
    "inpt = jnp.arange(4, dtype = jnp.float32)\n",
    "print('Input', inpt)\n",
    "print('Output', another_graph(inpt))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91bd43bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConcretizationTypeError",
     "evalue": "Abstract tracer value encountered where concrete value is expected: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\nThe problem arose with the `float` function. If trying to convert the data type of a value, try using `x.astype(float)` or `jnp.array(x, float)` instead.\nThe error occurred while tracing the function another_graph at /tmp/ipykernel_4263/1389991900.py:1 for make_jaxpr. This concrete value was not available in Python because it depends on the value of the argument x.\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConcretizationTypeError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4263/1172968850.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manother_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4263/1389991900.py\u001b[0m in \u001b[0;36manother_graph\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/jax/_src/core.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m   1357\u001b[0m                       f\"or `jnp.array(x, {fun.__name__})` instead.\")\n\u001b[1;32m   1358\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mConcretizationTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConcretizationTypeError\u001b[0m: Abstract tracer value encountered where concrete value is expected: Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>\nThe problem arose with the `float` function. If trying to convert the data type of a value, try using `x.astype(float)` or `jnp.array(x, float)` instead.\nThe error occurred while tracing the function another_graph at /tmp/ipykernel_4263/1389991900.py:1 for make_jaxpr. This concrete value was not available in Python because it depends on the value of the argument x.\n\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError"
     ]
    }
   ],
   "source": [
    "jax.make_jaxpr(another_graph)(inpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "416eefc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22m; a\u001b[35m:f32[3]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
       "    \u001b[39m\u001b[22m\u001b[22mb\u001b[35m:f32[3]\u001b[39m = integer_pow[y=2] a\n",
       "    c\u001b[35m:f32[]\u001b[39m = reduce_sum[axes=(0,)] b\n",
       "    d\u001b[35m:f32[]\u001b[39m = sqrt c\n",
       "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(d,) }"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_list = []\n",
    "\n",
    "# Invalid function with side-effect\n",
    "def norm(x):\n",
    "    global_list.append(x)\n",
    "    x = x ** 2\n",
    "    n = x.sum()\n",
    "    n = jnp.sqrt(n)\n",
    "    return n\n",
    "\n",
    "jax.make_jaxpr(norm)(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ace2b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient [1.3333334 2.        2.6666667]\n"
     ]
    }
   ],
   "source": [
    "grad_function = jax.grad(simple_graph)\n",
    "gradients = grad_function(inp)\n",
    "print('Gradient', gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d698fbad",
   "metadata": {},
   "source": [
    "# DataLoaders for Generative Models in Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa08543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Data\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b99cefff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9aa180",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_dataset = torchvision.datasets.MNIST()\n",
    "CIFAR_10_dataset = torchvision.datasets.CIFAR10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49e182cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data:str, batch_size, shuffle= True, num_workers:int =0):\n",
    "    '''\n",
    "    Arguments:\n",
    "    data_set: Give the name of the dataset \n",
    "    options available: MNIST or CIFAR10 or custom\n",
    "    batch_size: Number of mini-batches to create\n",
    "    shuffle: True, if shuffling of the dataset is enabled. False if not\n",
    "    Default shuffle = true\n",
    "    num_workers: Number of threads to use for preparing the dataset\n",
    "    returns Pytorch dataloader for the dataset\n",
    "    '''\n",
    "    if data == 'MNIST':\n",
    "        data_loader = torch.utils.data.DataLoader(MNIST_dataset,\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 shuffle = shuffle,\n",
    "                                                 num_workers = args.nThreads)\n",
    "    elif data == 'CIFAR10':\n",
    "        data_loader = torch.utils.data.DataLoader(CIFAR_10_dataset,\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 shuffle = shuffle,\n",
    "                                                 num_workers = args.nThreads)\n",
    "    elif data == 'CelebA64':\n",
    "        data_loader = torch.utils.data.DataLoader(celebA64_dataset,\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 shuffle = shuffle,\n",
    "                                                 num_workers = args.nThreads)\n",
    "    elif data == 'CelebA128':\n",
    "        data_loader = torch.utils.data.DataLoader(celebA128_dataset,\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 shuffle = shuffle,\n",
    "                                                 num_workers = args.nThreads)\n",
    "    elif data == 'custom':\n",
    "        data_loader = torch.utils.data.DataLoader(data,\n",
    "                                                 batch_size = batch_size,\n",
    "                                                 shuffle = shuffle,\n",
    "                                                 num_workers = args.nThreads)\n",
    "                  \n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6278c966",
   "metadata": {},
   "source": [
    "#### Pro Tip:\n",
    "Implement some basic training of models on standard datasets\n",
    "Examples:\n",
    "MNIST\n",
    "CIFAR100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8637b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import functools import partial\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from typing import Any,Tuple\n",
    "\n",
    "PRNGKey = jnp.ndarray\n",
    "\n",
    "num_devices = jax.device_count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb4d97",
   "metadata": {},
   "source": [
    "## Configuration settings for individual model components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872a96a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'z_dim': 64,\n",
    "    'seed': 41,\n",
    "    'batch_size':,\n",
    "    'epochs':,\n",
    "    'num_layers':,\n",
    "    \n",
    "}\n",
    "\n",
    "data_args= {\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "model_args= {\n",
    "    \n",
    "}\n",
    "\n",
    "util_args = {\n",
    "    \n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "hyper_parameters= {\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768c9adf",
   "metadata": {},
   "source": [
    "### Device configuration: CPU/ GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce8cef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25754370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************cpu found on the device******************\n",
      "************Running the Model Processes on cpu******************\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"***************{device} found on the device******************\" .format(device))\n",
    "print(f\"************Running the Model Processes on {device}******************\" .format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee26bde9",
   "metadata": {},
   "source": [
    "SEND TRAINING DATA TO GPU USING THE CODE:\n",
    "\n",
    "'''X_train = X_train.to(device)'''\n",
    "\n",
    "Testing and validation will take place on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7f6064",
   "metadata": {},
   "source": [
    "MODEL DECLARATION ON GPU\n",
    "model MyAwesomeneuralnetwork()\n",
    "model.to_device()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1856f7",
   "metadata": {},
   "source": [
    "## Vanilla-GAN Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223d3192",
   "metadata": {},
   "source": [
    "## Model Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "\n",
    "\n",
    "class Generator_network(hk.module):\n",
    "    \"\"\"Model declaration of Generator Network\"\"\"\n",
    "    def __init__(self, output_channels = output_channels, name = None):\n",
    "        super().__init__(name=name)\n",
    "        self.output_channels = output_channels\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        x = hk.Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24435d83",
   "metadata": {},
   "source": [
    "## GAN Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e46c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "@partial(jax.pmap, axis_name = 'num_devices')\n",
    "\n",
    "def generator_step(generator_state:TrainState, \n",
    "                   discriminator_state:TrainState,\n",
    "                   key: PRNGKey):\n",
    "    r\"\"\"\n",
    "    \"\"\"\n",
    "    input_noise = jax.random.normal(key, (args['batch_size'], args['z_dim']))\n",
    "    \n",
    "    \n",
    "    def loss_fn(params):\n",
    "        \n",
    "        \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7c086e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n",
      "Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "print(f\"Number of devices: {jax.device_count()}\")\n",
    "print(\"Device:\", jax.devices()[0].device_kind)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814ec85b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
